{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 04\n",
    "\n",
    "Name: **Bowen Li**  \n",
    "UID: **U79057147** \n",
    "\n",
    "### Topics\n",
    "\n",
    "- Distance & Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance & Similarity\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "a) In the minkowski distance, describe what the parameters p and d are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d$ is the dimension of the space in which the data points lie (# of coordinates in the data points).\n",
    "\n",
    "$p$ is the order to which the coordinate differences between the points are raised, and the root to apply to the sum. Larger values of $p$ will lead to smaller values for the distance between the same pair of data points. To demonstrate why, we can consider two points $A$ units apart on the $x$-axis and $B$ units apart on the $y$-axis. The Minkowski distance between these points can be written as $(A^p+B^p)^\\frac{1}{p}$. \n",
    "\n",
    "We can also say that $A^p+B^p = (A+B)^p-C$ for some nonnegative value $C$ (since $A$ and $B$ are nonnegative as they're the outputs of absolute value functions by definition of Minkowski distance). This also applies if there are more than two dimensions. \n",
    "\n",
    "As such we can rewrite the distance as $((A+B)^p-C)^\\frac{1}{p}$ which we can say is upper bounded by $((A+B)^p)^\\frac{1}{p}=A+B$ since the $x^\\frac{1}{p}$ function is monotonically increasing for positive $p$, so lower input values imply lower output values.\n",
    "\n",
    "This upper bound $A+B$ happens to be the Manhattan distance ($p=1$) and so for all the valid values of $p$, the Minkowski distance will be upper bounded by the Manhattan distance. In addition, higher values of $p$ will lead to higher values of $C$, thus subtracting more from the input to the root and thus lower distance values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In your own words describe the difference between the Euclidean distance and the Manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Euclidean distance is the straight-line distance between two points while the Manhattan distance is the distance traversed from one point to the other while only moving along one coordinate axis at a time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider A = (0, 0) and B = (1, 1). When:\n",
    "\n",
    "- p = 1, d(A, B) = 2\n",
    "- p = 2, d(A, B) = $\\sqrt{2} = 1.41$\n",
    "- p = 3, d(A, B) = $2^{1/3} = 1.26$\n",
    "- p = 4, d(A, B) = $2^{1/4} = 1.19$\n",
    "\n",
    "c) Describe what you think distance would look like when p is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance would approach 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Is the minkowski distance still a distance function when p < 1? Expain why / why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No; consider the case where $p=\\frac{1}{2}$ and $d=2$ with the points $A(0,0)$, $B(1,0)$, and $C(0,1)$.\n",
    "\n",
    "We could go from $B$ to $C$ directly which would be $D(B,C) = (1^\\frac{1}{2} + 1^\\frac{1}{2})^2=4$.\n",
    "\n",
    "Alternatively, we could go through $A$, which would be $D(B,A)+D(A,C)=(1^\\frac{1}{2}+0^\\frac{1}{2})^2+(0^\\frac{1}{2}+1^\\frac{1}{2})^2=1+1=2$\n",
    "\n",
    "But now $D(B,A)+D(A,C) < D(B,C)$ which violates the triangle inequality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) when would you use cosine similarity over the euclidan distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to focus on the directional similarities between two data points regardless of their magnitudes (i.e. documents on differing lengths (magnitudes) but discussing similar topics (direction))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) what does the jaccard distance account for that the manhattan distance doesn't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard distance accounts for the intersection of the data points while manhattan distance doesn't."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "\n",
    "Consider the following two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"hello my name is Alice\"  \n",
    "s2 = \"hello my name is Bob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the union of words from both sentences, we can represent each sentence as a vector. Each element of the vector represents the presence or absence of the word at that index.\n",
    "\n",
    "In this example, the union of words is (\"hello\", \"my\", \"name\", \"is\", \"Alice\", \"Bob\") so we can represent the above sentences as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = [1,    1, 1,   1, 1,    0]\n",
    "#     hello my name is Alice\n",
    "v2 = [1,    1, 1,   1, 0, 1]\n",
    "#     hello my name is    Bob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatically, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'is', 'hello', 'Bob', 'name', 'my']\n",
      "[1, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "corpus = [s1, s2]\n",
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)\n",
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a new sentence to our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"hi my name is Claude\"\n",
    "corpus.append(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is the new union of words used to represent s1, s2, and s3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'hi', 'is', 'Claude', 'hello', 'Bob', 'name', 'my']\n"
     ]
    }
   ],
   "source": [
    "all_words = list(set([item for x in corpus for item in x.split()]))\n",
    "print(all_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Represent s1, s2, and s3 as vectors as above, using this new set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 1]\n",
      "[0, 0, 1, 0, 1, 1, 1, 1]\n",
      "[0, 1, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "v1 = [1 if x in s1 else 0 for x in all_words]\n",
    "v2 = [1 if x in s2 else 0 for x in all_words]\n",
    "v3 = [1 if x in s3 else 0 for x in all_words]\n",
    "\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that computes the manhattan distance between two vectors. Which pair of vectors are the most similar under that distance function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "def minkowski_distance(x, y, p):\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError(\"x and y should be the same dimension\")\n",
    "\n",
    "    res = 0\n",
    "    for i in range(len(x)):\n",
    "        res += abs(x[i] - y[i]) ** p\n",
    "\n",
    "    return res ** (1/p)\n",
    "\n",
    "print(minkowski_distance([0,0], [1,1], 2))\n",
    "print(minkowski_distance([0,0], [1,1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "2.0\n",
      "4.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "def manhattan_distance(x, y):\n",
    "    return minkowski_distance(x, y, 1)\n",
    "\n",
    "print(manhattan_distance([0,0], [3,4]))\n",
    "print(manhattan_distance(v1, v2))\n",
    "print(manhattan_distance(v1, v3))\n",
    "print(manhattan_distance(v2, v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors `v1` and `v2` have the least distance between them and are thus the most similar under Manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create a matrix of all these vectors (row major) and add the following sentences in vector form:\n",
    "\n",
    "- \"hi Alice\"\n",
    "- \"hello Claude\"\n",
    "- \"Bob my name is Claude\"\n",
    "- \"hi Claude my name is Alice\"\n",
    "- \"hello Bob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 1, 0, 1, 0, 1, 1], [0, 0, 1, 0, 1, 1, 1, 1], [0, 1, 1, 1, 0, 0, 1, 1], [1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 1, 1, 0, 1, 1, 1], [1, 1, 1, 1, 0, 0, 1, 1], [0, 0, 0, 0, 1, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "s4 = \"hi Alice\"\n",
    "s5 = \"hello Claude\"\n",
    "s6 = \"Bob my name is Claude\"\n",
    "s7 = \"hi Claude my name is Alice\"\n",
    "s8 = \"hello Bob\"\n",
    "\n",
    "new_sentences = [s4, s5, s6, s7, s8]\n",
    "\n",
    "matrix = [v1, v2, v3]\n",
    "\n",
    "for sentence in new_sentences:\n",
    "    vector_sentence = [1 if x in sentence else 0 for x in all_words]\n",
    "    matrix.append(vector_sentence)\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) How many rows and columns does this matrix have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 8\n",
      "Columns: 8\n"
     ]
    }
   ],
   "source": [
    "rows = len(matrix)\n",
    "cols = len(matrix[0]) if len(matrix) else 0\n",
    "\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Columns:\", cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) When using the Manhattan distance, which two sentences are the most similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.0, [(1, 2)])\n"
     ]
    }
   ],
   "source": [
    "def get_min_manhattan_distance(vectors):\n",
    "    num_vectors = len(vectors)\n",
    "    if num_vectors < 2:\n",
    "        return 0\n",
    "\n",
    "    min_dist = manhattan_distance(vectors[0], vectors[1])\n",
    "    closest_vector_pairs = [(0,1)]\n",
    "    for i in range(num_vectors):\n",
    "        for j in range(i+1, num_vectors):\n",
    "            dist_ij = manhattan_distance(vectors[i], vectors[j])\n",
    "            \n",
    "            if dist_ij < min_dist:\n",
    "                min_dist = dist_ij\n",
    "                closest_vector_pairs = [(i,j)]\n",
    "            elif dist_ij == min_dist:\n",
    "                closest_vector_pairs.append((i,j))\n",
    "\n",
    "    return min_dist, closest_vector_pairs\n",
    "\n",
    "test_mat = [[0,0], [3,1], [3,3]]\n",
    "print(get_min_manhattan_distance(test_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, [(2, 6)])\n"
     ]
    }
   ],
   "source": [
    "print(get_min_manhattan_distance(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence 3, \"hi my name is Claude\" and sentence 7, \"hi Claude my name is Alice\" are the most similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of graphs $\\mathcal{G}$, each graph $G \\in \\mathcal{G}$ is defined over the same set of nodes $V$. The graphs are represented by their adjacency matrices, which are 2D arrays where each element indicates whether a pair of nodes is connected by an edge.\n",
    "\n",
    "Your task is to compute the pairwise distances between these graphs based on a specific distance metric. The distance $d(G, G')$ between two graphs $G = (V, E)$ and $G' = (V, E')$ is defined as the sum of the number of edges in $G$ but not in $G'$, and the number of edges in $G'$ but not in $G$. Mathematically, this can be expressed as:\n",
    "\n",
    "$$\n",
    "d(G, G') = |E \\setminus E'| + |E' \\setminus E|.\n",
    "$$\n",
    "\n",
    "##### Requirements:\n",
    "1. **Input**: Should take a list of 2D numpy arrays as input. Each array represents the adjacency matrix of a graph.\n",
    "\n",
    "2. **Output**: Should output a pairwise distance matrix. If there are $n$ graphs in the input list, the output should be an $n \\times n$ matrix where the entry at position $(i, j)$ represents the distance between the $i^{th}$ and $j^{th}$ graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "3.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def graph_distance(adj1, adj2):\n",
    "    if adj1.shape != adj2.shape:\n",
    "        raise ValueError(\"Incompatible adjacency matrices\")\n",
    "\n",
    "    exclusive_entries = np.logical_xor(adj1, adj2)\n",
    "    diagonal_sum = np.sum(exclusive_entries.diagonal())\n",
    "\n",
    "    double_edges_count = np.sum(exclusive_entries) + diagonal_sum # Assume matrix is symmetric (undirected)\n",
    "    \n",
    "    return double_edges_count / 2\n",
    "\n",
    "g1 = np.array([[0,1,0],\n",
    "               [1,1,0],\n",
    "               [0,0,1]])\n",
    "\n",
    "g2 = np.array([[1,1,0],\n",
    "               [1,0,0],\n",
    "               [0,0,1]])\n",
    "\n",
    "g3 = np.array([[1,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,1]])\n",
    "\n",
    "print(graph_distance(g1,g2)) # expect 2\n",
    "print(graph_distance(g1,g3)) # expect 3\n",
    "print(graph_distance(g2,g3)) # expect 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
